---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.5.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import pandas as pd
import numpy as np
import librosa
import glob

from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, LSTM
from tensorflow.keras.utils import to_categorical

from matplotlib import pyplot
```

```{python}
# se usa del GPU
#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#print(device)
```

```{python}
# se lee el dataframe
#df = pd.read_csv("UrbanSound8K/metadata/UrbanSound8K.csv")
#df.head()
```

```{python}
def grab_sound_features(filename):
    sample_rate = 12000
    duration = 3

    # Cargamos el audio
    X, sample_rate = librosa.load(filename, sr=sample_rate, res_type='kaiser_fast')
    n_sample = X.shape[0]
    n_sample_fit = int(duration*sample_rate)

    # Si el audio es muy grande, limitamos la duracion del audio.
    # Si es audio es muy pequeño se completa con ceros.
    # En ambos casos ponemos un silencio de 0.5 segundos
    if n_sample < n_sample_fit:
        X = np.hstack((0.5*sample_rate, X, np.zeros(n_sample_fit - n_sample)))
    elif n_sample > n_sample_fit:
        X = np.hstack((0.5*sample_rate, X[int((n_sample-n_sample_fit)/2):int((n_sample+n_sample_fit)/2)]))
    
    return librosa.feature.melspectrogram(y=X, sr=sample_rate).transpose()

def parser():
    feature = []
    label = []
    # Funcion para cargar archivos y extraer caracteristicas
    for filename in glob.glob("data/scream/*.wav"):
        mels = grab_sound_features(filename)
        feature.append(mels)
        label.append(1)
    for filename in glob.glob("data/no-scream/*.wav"):
        mels = grab_sound_features(filename)
        feature.append(mels)
        label.append(0)
    return [feature, label]
```

```{python}
data = np.array(parser())
n = data.shape[1]
```

```{python}
data[0,0].shape
```

```{python}
X_ = data[0, :]
Y = data[1, :]
print(X_.shape, Y.shape)
X = np.empty([n, data[0,0].shape[0], data[0,0].shape[1]])
```

```{python}
for i in range(n):
    X[i] = (X_[i])
```

```{python}
# Convertimos los labels a 2-D
Y = np.tile(Y,(data[0,0].shape[0],1)).transpose()
```

```{python}
Y = to_categorical(Y)
```

```{python}
'''Final Data'''
print(X.shape)
print(Y.shape)
```

```{python}
# se conforman los conjuntos de entrenamiento y prueba
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)
```

```{python}
# se ajusta el tamaño de los sets
#X_train = X_train.reshape(X_train.shape[0], 16, 8, 1)
#X_test = X_test.reshape(X_test.shape[0], 16, 8, 1)
```

```{python}
#input_dim = (16, 8, 1)
```

```{python}
input_dim = (X_train.shape[1], X_train.shape[2])
```

```{python}
input_dim
```

```{python}
# Crea el modelo en tensorflow keras
model = Sequential()

# Definimos un modelo LSTM many-to-many
model.add(LSTM(units=256, dropout=0.05, recurrent_dropout=0.35, return_sequences=True, input_shape=input_dim))
model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.35, return_sequences=True))
model.add(LSTM(units=64,  dropout=0.05, recurrent_dropout=0.35, return_sequences=True))
model.add(LSTM(units=32,  dropout=0.05, recurrent_dropout=0.35, return_sequences=True))
model.add(Dense(units=2, activation="softmax"))

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

model.summary()
```

```{python}
# se entrena el modelo en 50 epocas
history = model.fit(X_train, Y_train, epochs = 50, validation_data = (X_test, Y_test))
```

```{python}
# se muestra el accuracy final obtenido
predictions = model.predict(X_test)
score = model.evaluate(X_test, Y_test)
print(score)
```

```{python}
# Guardar el Modelo
model.save('lstm.h5')
```

```{python}
# plot history
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.xlabel('Epochs', fontsize = 12)
pyplot.ylabel('Loss', fontsize = 12)
pyplot.show()
pyplot.plot(history.history['accuracy'], label='train')
pyplot.plot(history.history['val_accuracy'], label='test')
pyplot.legend()
pyplot.xlabel('Epochs', fontsize = 12)
pyplot.ylabel('Accuracy', fontsize = 12)
pyplot.show()
```
